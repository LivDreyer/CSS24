{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n",
    "### Group 14 \n",
    "\n",
    "> Github repository: https://github.com/LivDreyer/CSS24.git\n",
    "\n",
    "> Shortlog of git commits:\n",
    "- x  LivDreyer\n",
    "- x  AIAndreas\n",
    "- x  FelixxAI\n",
    "\n",
    "\n",
    "> Contribution: The workload was distributed equally between all members of the group. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Crowd](crowd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import networkx as nx\n",
    "import netwulf as nu\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is our dataset? \n",
    "- What is our motivation for choosing this data set? \n",
    "- What was your goal for the end user's experience? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to answer the research question: \"What is the relationship between artist collaboration patterns, popularity, and lyrical expression of genre themes?\". To answer this question, we decided to center our network analysis around the worlds largest music streaming service: Spotify. Given our project's focus on artist popularity, using a platform such as Spotify for insights is logical. With streaming services contributing to 84% of the music industry's revenue, and Spotify holding a dominant market share of 30.5%, it offers a comprehensive insight to artist popularity. \n",
    "\n",
    "For the textual analysis, Genius, among others, serve as an \"online music encyclopidia\". Although the textual analysis in this project could utilize a variety of song lyric API's, Genius offers the ability for artists and users to annotate lyrics, making it an interesting choice for other analyses in the future. \n",
    "\n",
    "This projects takes starting point in the Kaggle dataset \"US Top 10K Artists and Their Popular Songs\". The dataset, created by Spoorthi Uday Karakaraddi, was collected using the Spotify API and features several attributes of the top 10k artists in the US in 2023. It serves as the foundation for constructing the final dataset used for network analysis, which is then used for constructing the dataset for our textual analysis. \n",
    "\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Genius_(company)\n",
    "- https://www.kaggle.com/datasets/spoorthiuk/us-top-10k-artists-and-their-popular-songs \n",
    "- https://explodingtopics.com/blog/music-streaming-stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and basic statistics \n",
    "\n",
    "Since this project is working with API's, we are constructing the datasets from this data taking our starting point, as mentioned, in the Kaggle dataset \"US Top 10k Artists and Their Popular Songs\". To provide a clear explanation of our course of action, this data section will be divided into the construction of the dataset used for network analysis and subsequently the one used for the text analysis after the initial work of fetching data from the Spotify API. Each block of code will be labeled with the name of the resulting csv-file. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Note:** In this project, a collaboration between two artists is considered one if an artist have a featuring artist on their songs. An example could be the artist \"Rihanna\". On her song titled \"Consideration\", we see the artist \"SZA\" is featured, which in this project will be considered a collaboration. To explore artists collaboration patterns, we used the \"US Top 10K Artists and Their Popular Songs\"-dataset to create our first list of artists.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data from the Spotify API\n",
    "\n",
    "The first query from the Spotify API consisted of retrieving the top 10 tracks of each artist to reveal possible featuring artists. Due to a rate limit of 5000 requests per day on queries from the Spotify API, with the API key being valid for only one hour, only the top 4250 artists, ranked by Spotify's measure of popularity, from the Kaggle dataset was used. This resulted in a dataframe of the song ID, song Name, main artist, featured artist(s) of the song, and the genre of the song. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete_Songs_with_Artists_and_Features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Spotify API credentials\n",
    "client_id = '#'  \n",
    "client_secret = '#'  \n",
    "\n",
    "def refresh_token():\n",
    "    \"\"\" Refresh the Spotify API token. \"\"\"\n",
    "    url = 'https://accounts.spotify.com/api/token'\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(url, auth=(client_id, client_secret), data=payload)\n",
    "    if response.status_code == 200:\n",
    "        new_token = response.json()['access_token']\n",
    "        logging.info(\"Token refreshed successfully.\")\n",
    "        return new_token\n",
    "    else:\n",
    "        logging.error(f\"Failed to refresh token: {response.text}\")\n",
    "        raise Exception(\"Failed to refresh token\")\n",
    "\n",
    "# Initial token\n",
    "token = refresh_token()\n",
    "headers = {'Authorization': f'Bearer {token}'}\n",
    "\n",
    "def get_top_tracks(artist_id, retry_count=0):\n",
    "    \"\"\" Fetch top tracks for a given artist ID from Spotify, handling rate limits dynamically. \"\"\"\n",
    "    global headers\n",
    "    top_tracks_url = f\"https://api.spotify.com/v1/artists/{artist_id}/top-tracks?country=US\"\n",
    "    response = requests.get(top_tracks_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [(track['id'], track['name'], [artist['name'] for artist in track['artists']]) for track in data.get('tracks', [])]\n",
    "    elif response.status_code == 429:\n",
    "        retry_after = int(response.headers.get(\"Retry-After\", 30))\n",
    "        wait_time = min(retry_after, 30)  # Cap at 30 seconds to avoid overly long delays\n",
    "        logging.warning(f\"Rate limit exceeded, retrying after {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        return get_top_tracks(artist_id, retry_count + 1) if retry_count < 5 else []\n",
    "    elif response.status_code == 401 and retry_count < 5:\n",
    "        logging.warning(\"Token expired, refreshing token...\")\n",
    "        headers['Authorization'] = 'Bearer ' + refresh_token()\n",
    "        return get_top_tracks(artist_id, retry_count + 1)\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def separate_artists(artists, main_artist_name):\n",
    "    \"\"\" Separate main artist from featured artists. \"\"\"\n",
    "    featured_artists = [artist for artist in artists if artist != main_artist_name]\n",
    "    return main_artist_name, ', '.join(featured_artists)\n",
    "\n",
    "def gather_top_tracks(df):\n",
    "    \"\"\" Process each artist and fetch their top tracks. \"\"\"\n",
    "    songs = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Fetching top tracks\"):\n",
    "        artist_id = row['ID']\n",
    "        results = get_top_tracks(artist_id)\n",
    "        for song_id, song_name, artists in results:\n",
    "            main_artist, features = separate_artists(artists, row['Name'])\n",
    "            songs.append([song_id, song_name, main_artist, features])\n",
    "    return songs\n",
    "\n",
    "\n",
    "df_artists = pd.read_csv('Artists.csv')\n",
    "first_part = df_artists.iloc[:4250]\n",
    "logging.info(\"Processing the first 4250 artists...\")\n",
    "song_data = gather_top_tracks(first_part)\n",
    "songs_df = pd.DataFrame(song_data, columns=['Song ID', 'Song Name', 'Main Artist', 'Featured Artists', 'Genres'])\n",
    "\n",
    "# Save the data to CSV\n",
    "songs_df.to_csv('Complete_Songs_with_Artists_and_Features.csv', index=False)\n",
    "logging.info(\"Data saved to Complete_Songs_with_Artists_and_Features.csv.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then created a dataframe of the 4250 artists from the Kaggle dataset containing the following information: Main artist, Top 10 tracks, Artist ID, Genre (categorized by Spotify), Popularity Score, Follower Count, and their URI. See the following code block. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final_Artist_Tracks_Info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "songs_df = pd.read_csv('Complete_Songs_with_Artists_and_Features.csv')\n",
    "artists_info_df = pd.read_csv('Artists.csv')\n",
    "\n",
    "songs_df['Main Artist'] = songs_df['Main Artist'].str.strip().str.lower()\n",
    "artists_info_df['Name'] = artists_info_df['Name'].str.strip().str.lower()\n",
    "top_tracks = songs_df.groupby('Main Artist')['Song Name'].apply(list).reset_index()\n",
    "top_tracks.rename(columns={'Main Artist': 'Name'}, inplace=True)\n",
    "final_df = pd.merge(top_tracks, artists_info_df, on='Name', how='left')\n",
    "final_df.rename(columns={'Name': 'Main Artist'}, inplace=True)\n",
    "final_df = final_df[['Main Artist', 'Song Name', 'ID', 'Genres', 'Popularity', 'Followers', 'URI']]\n",
    "\n",
    "# Save the final merged dataset to a new CSV file\n",
    "final_df.to_csv('Final_Artist_Tracks_Info.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now both have a dataframe of the first 4250 artists and the attributes previously mentioned and know which artists are featured on those 4250 artists top tracks. We will now query the same information for the featured artists, so we can merge the data, creating a final dataset.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete_Artists_Info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from tqdm import tqdm\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"#\", client_secret=\"#\"))\n",
    "\n",
    "# Function to search for an artist on Spotify and get their info\n",
    "def get_artist_info(artist_name):\n",
    "    try:\n",
    "        results = sp.search(q='artist:' + artist_name, type='artist', limit=1)\n",
    "        items = results['artists']['items']\n",
    "        if items:\n",
    "            artist = items[0]\n",
    "            return {\n",
    "                'Name': artist['name'],\n",
    "                'ID': artist['id'],\n",
    "                'Genres': ', '.join(artist['genres']),\n",
    "                'Popularity': artist['popularity'],\n",
    "                'Followers': artist['followers']['total'],\n",
    "                'URI': artist['uri']\n",
    "            }\n",
    "    except spotipy.client.SpotifyException as e:\n",
    "        print(f\"Spotify API error for {artist_name}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Read the text file with artist names\n",
    "with open('Unique_Features.txt', 'r') as file:\n",
    "    unique_features = file.read().splitlines()\n",
    "\n",
    "artists_to_query = unique_features\n",
    "artists_info = []\n",
    "for artist_name in tqdm(artists_to_query, desc='Querying artists'):\n",
    "    artist_info = get_artist_info(artist_name)\n",
    "    if artist_info:\n",
    "        artists_info.append(artist_info)\n",
    "    else:\n",
    "        print(f\"No data found for artist: {artist_name}\")\n",
    "\n",
    "artists_df = pd.DataFrame(artists_info)\n",
    "artists_df.to_csv('Complete_Artists_Info.csv', index=False)\n",
    "print(\"Finished collecting all artists' information.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now found the following information on the featured artists: Artist, Top 10 tracks, Artist ID, Genre (categorized by Spotify), Popularity Score, Follower Count, and their URI. To obtain the top 10 tracks for each of the featuring artists, who are now just denoted as artists as well, we query the Spotify API yet again. As we are now interested in the top 10 tracks of 11260 artists, we carry out the following code in three sections. For every run of the code, we obtain about 4000 artists songs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following two blocks of code results in Feature_Artist_Songs_Combined.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Spotify API credentials\n",
    "client_id = '#'  \n",
    "client_secret = '#'  \n",
    "\n",
    "def refresh_token():\n",
    "    \"\"\" Refresh the Spotify API token. \"\"\"\n",
    "    url = 'https://accounts.spotify.com/api/token'\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(url, auth=(client_id, client_secret), data=payload)\n",
    "    if response.status_code == 200:\n",
    "        new_token = response.json()['access_token']\n",
    "        logging.info(\"Token refreshed successfully.\")\n",
    "        return new_token\n",
    "    else:\n",
    "        logging.error(f\"Failed to refresh token: {response.text}\")\n",
    "        raise Exception(\"Failed to refresh token\")\n",
    "\n",
    "# Initial token\n",
    "token = refresh_token()\n",
    "headers = {'Authorization': f'Bearer {token}'}\n",
    "\n",
    "def get_top_tracks(artist_id, retry_count=0):\n",
    "    \"\"\"Fetch top tracks for a given artist ID from Spotify, handling rate limits dynamically.\"\"\"\n",
    "    global headers\n",
    "    top_tracks_url = f\"https://api.spotify.com/v1/artists/{artist_id}/top-tracks?country=US\"\n",
    "    response = requests.get(top_tracks_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [(track['id'], track['name'], [artist['name'] for artist in track['artists']]) for track in data.get('tracks', [])]\n",
    "    elif response.status_code == 429:\n",
    "        retry_after = int(response.headers.get(\"Retry-After\", 30))\n",
    "        wait_time = min(retry_after, 30)  # Cap at 30 seconds to avoid overly long delays\n",
    "        logging.warning(f\"Rate limit exceeded, retrying after {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        return get_top_tracks(artist_id, retry_count + 1) if retry_count < 5 else []\n",
    "    elif response.status_code == 401 and retry_count < 5:\n",
    "        logging.warning(\"Token expired, refreshing token...\")\n",
    "        headers['Authorization'] = 'Bearer ' + refresh_token()\n",
    "        return get_top_tracks(artist_id, retry_count + 1)\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def separate_artists(artists, main_artist_name):\n",
    "    \"\"\"Separate main artist from featured artists.\"\"\"\n",
    "    featured_artists = [artist for artist in artists if artist != main_artist_name]\n",
    "    return main_artist_name, ', '.join(featured_artists)\n",
    "\n",
    "def gather_top_tracks(df):\n",
    "    \"\"\"Process each artist and fetch their top tracks.\"\"\"\n",
    "    songs = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Fetching top tracks\"):\n",
    "        artist_id = row['ID']\n",
    "        results = get_top_tracks(artist_id)\n",
    "        for song_id, song_name, artists in results:\n",
    "            main_artist, features = separate_artists(artists, row['Name'])\n",
    "            songs.append([song_id, song_name, main_artist, features])\n",
    "    return songs\n",
    "\n",
    "# Load the dataset\n",
    "df_artists = pd.read_csv('Complete_Artists_Info.csv')\n",
    "\n",
    "# Split the dataset into 3 parts\n",
    "#first_half = df_artists.iloc[:4300]\n",
    "#first_half = df_artists.iloc[4300:8600]\n",
    "first_half = df_artists.iloc[8600:]\n",
    "\n",
    "\n",
    "logging.info(\"Processing the first half of the dataset...\")\n",
    "first_half_data = gather_top_tracks(first_half)\n",
    "songs_df = pd.DataFrame(first_half_data, columns=['Song ID', 'Song Name', 'Main Artist', 'Featured Artists'])\n",
    "#songs_df.to_csv('Feature_Artist_Songs_Part1.csv', index=False)\n",
    "#songs_df.to_csv('Feature_Artist_Songs_Part2.csv', index=False)\n",
    "songs_df.to_csv('Feature_Artist_Songs_Part3.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are then merged into one single dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each part of the dataset\n",
    "df_part1 = pd.read_csv('Feature_Artist_Songs_Part1.csv')\n",
    "df_part2 = pd.read_csv('Feature_Artist_Songs_Part2.csv')\n",
    "df_part3 = pd.read_csv('Feature_Artist_Songs_Part3.csv')\n",
    "\n",
    "df_combined = pd.concat([df_part1, df_part2, df_part3], ignore_index=True)\n",
    "df_combined.to_csv('Feature_Artist_Songs_Combined.csv', index=False)\n",
    "\n",
    "print(\"Combined DataFrame Info:\")\n",
    "print(df_combined.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a full dataset of featured artists and their top 10 songs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final_Feature_Artist_Tracks_Info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "songs_df = pd.read_csv('Feature_Artist_Songs_Combined.csv')\n",
    "artists_info_df = pd.read_csv('Featured/Complete_Feature_Artists_Info.csv')\n",
    "\n",
    "# Normalize artist names to ensure the case and trimming issues don't affect the merge\n",
    "songs_df['Main Artist'] = songs_df['Main Artist'].str.strip().str.lower()\n",
    "artists_info_df['Name'] = artists_info_df['Name'].str.strip().str.lower()\n",
    "\n",
    "# Aggregate the top tracks for each main artist\n",
    "top_tracks = songs_df.groupby('Main Artist')['Song Name'].apply(list).reset_index()\n",
    "top_tracks.rename(columns={'Main Artist': 'Name'}, inplace=True)\n",
    "final_df = pd.merge(top_tracks, artists_info_df, on='Name', how='left')\n",
    "final_df.rename(columns={'Name': 'Main Artist'}, inplace=True)\n",
    "final_df = final_df[['Main Artist', 'Song Name', 'ID', 'Genres', 'Popularity', 'Followers', 'URI']]\n",
    "final_df.to_csv('Final_Feature_Artist_Tracks_Info.csv', index=False)\n",
    "\n",
    "print(\"Final DataFrame head:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we combine the *Final_Feature_Artist_Tracks_Info.csv* and *Final_Artist_Tracks_Info.csv* into one dataframe with the following attributes: Artist, Top songs, Artist ID, Genre, Popularity score, Followers, and URI. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combined_Artist_Tracks_Info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "featured_tracks = pd.read_csv('Featured\\\\Final_Feature_Artist_Tracks_Info.csv')\n",
    "final_artist_tracks = pd.read_csv('Final_Artist_Tracks_Info.csv')\n",
    "\n",
    "combined_data = pd.concat([featured_tracks, final_artist_tracks], ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "combined_data.to_csv('Combined_Artist_Tracks_Info.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now fetched all data needed from the Spotify API. The following sections will be divided into the data used for the network analysis followed by the data used for the textual analysis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and basic statistics - Network Analysis \n",
    "\n",
    "For the network analysis, we will use the following csv-files created en the previous section: \n",
    "\n",
    "- Final_Feature_Artist_Tracks_Info.csv\n",
    "- Feature_Artist_Songs_Combined.csv\n",
    "- Complete_Songs_with_Artists_and_Features.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the final dataset used for the network analysis, we first take *Final_Feature_Artist_Tracks_Info.csv* with the attributes Main Artist, Genre, Popularity Score, and Followers and join on \"Main Artist\" with *Feature_Artist_Songs_Combined.csv* that have the attributes Song Name, Main Artist and Featured Artist(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist = pd.read_csv('Artists.csv')\n",
    "\n",
    "df1 = pd.read_csv('Complete_Songs_with_Artists_and_Features.csv', usecols=['Song Name','Main Artist', 'Featured Artists'])\n",
    "\n",
    "merged_df = df1.merge(df_artist, left_on='Main Artist', right_on='Name', how='left')\n",
    "\n",
    "df1_with_data = merged_df.drop(columns=['Name', 'ID', 'URI', 'Age', 'Country', 'Gender'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then join *Complete_Songs_with_Artists_and_Features.csv* with the Kaggle \"US 10k Top Artists and Their Popular Songs\"-dataset on the name of the Main Artist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Feature_Artist_Songs_Combined.csv', usecols=['Song Name','Main Artist', 'Featured Artists'])\n",
    "\n",
    "df3 = pd.read_csv('Final_Feature_Artist_Tracks_info.csv', usecols=['Main Artist', 'Genres', 'Popularity', 'Followers'])\n",
    "\n",
    "df2['Main Artist'] = df2['Main Artist'].str.lower()\n",
    "\n",
    "merged_df = df2.merge(df3, on='Main Artist', how='inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we combine the two dataframes, resulting in the final one shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_with_data['Main Artist'] = df1_with_data['Main Artist'].str.lower()\n",
    "merged_df = merged_df[~merged_df['Main Artist'].isin(df1_with_data['Main Artist'])]\n",
    "\n",
    "extended_df = pd.concat([df1_with_data, merged_df], ignore_index=True)\n",
    "\n",
    "cleaned_df = extended_df.drop_duplicates()\n",
    "cleaned_df.reset_index(drop=True, inplace=True)\n",
    "cleaned_df.to_csv('Final_Songs_with_Artists_and_Features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show df \n",
    "cleaned_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
