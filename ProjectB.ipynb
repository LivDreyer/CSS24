{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n",
    "### Group 14 \n",
    "\n",
    "> Github repository: https://github.com/LivDreyer/CSS24.git\n",
    "\n",
    "> Shortlog of git commits:\n",
    "- x  LivDreyer\n",
    "- x  AIAndreas\n",
    "- x  FelixxAI\n",
    "\n",
    "\n",
    "> Contribution: The workload was distributed equally between all members of the group. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Crowd](crowd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import networkx as nx\n",
    "import netwulf as nu\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is our dataset? \n",
    "- What is our motivation for choosing this data set? \n",
    "- What was your goal for the end user's experience? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to answer the research question: \"What is the relationship between artist collaboration patterns, popularity, and lyrical expression of genre themes?\". To answer this question, we decided to center our network analysis around the worlds largest music streaming service: Spotify. Given our project's focus on artist popularity, using a platform such as Spotify for insights is logical. With streaming services contributing to 84% of the music industry's revenue, and Spotify holding a dominant market share of 30.5%, it offers a comprehensive insight to artist popularity. \n",
    "\n",
    "For the textual analysis, Genius, among others, serve as an \"online music encyclopidia\". Although the textual analysis in this project could utilize a variety of song lyric API's, Genius offers the ability for artists and users to annotate lyrics, making it an interesting choice for other analyses in the future. \n",
    "\n",
    "This projects takes starting point in the Kaggle dataset \"US Top 10K Artists and Their Popular Songs\". The dataset, created by Spoorthi Uday Karakaraddi, was collected using the Spotify API and features several attributes of the top 10k artists in the US in 2023. It serves as the foundation for constructing the final dataset used for network analysis, which is then used for constructing the dataset for our textual analysis. \n",
    "\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Genius_(company)\n",
    "- https://www.kaggle.com/datasets/spoorthiuk/us-top-10k-artists-and-their-popular-songs \n",
    "- https://explodingtopics.com/blog/music-streaming-stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, a collaboration between two artists is considered one if an artist have a featuring artist on their songs. An example could be the artist \"Rihanna\". On her song titled \"Consideration\", we see the artist \"SZA\" is featured, which in this project will be considered a collaboration. To explore artists collaboration patterns, we used the \"US Top 10K Artists and Their Popular Songs\"-dataset to create our first list of artists.  \n",
    "\n",
    "The first query from the Spotify API consisted of retrieving the top 10 tracks of each artist to reveal possible featuring artists. Due to a rate limit of 5000 requests per day on queries from the Spotify API, with the API key being valid for only one hour, only the top 4250 artists, ranked by Spotify's measure of popularity, from the Kaggle dataset was used. This resulted in a dataframe of the song ID, song Name, main artist, featured artist(s) of the song, and the genre of the song. Please see code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Spotify API credentials\n",
    "client_id = '#'  \n",
    "client_secret = '#'  \n",
    "\n",
    "def refresh_token():\n",
    "    \"\"\" Refresh the Spotify API token. \"\"\"\n",
    "    url = 'https://accounts.spotify.com/api/token'\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(url, auth=(client_id, client_secret), data=payload)\n",
    "    if response.status_code == 200:\n",
    "        new_token = response.json()['access_token']\n",
    "        logging.info(\"Token refreshed successfully.\")\n",
    "        return new_token\n",
    "    else:\n",
    "        logging.error(f\"Failed to refresh token: {response.text}\")\n",
    "        raise Exception(\"Failed to refresh token\")\n",
    "\n",
    "# Initial token\n",
    "token = refresh_token()\n",
    "headers = {'Authorization': f'Bearer {token}'}\n",
    "\n",
    "def get_top_tracks(artist_id, retry_count=0):\n",
    "    \"\"\" Fetch top tracks for a given artist ID from Spotify, handling rate limits dynamically. \"\"\"\n",
    "    global headers\n",
    "    top_tracks_url = f\"https://api.spotify.com/v1/artists/{artist_id}/top-tracks?country=US\"\n",
    "    response = requests.get(top_tracks_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [(track['id'], track['name'], [artist['name'] for artist in track['artists']]) for track in data.get('tracks', [])]\n",
    "    elif response.status_code == 429:\n",
    "        retry_after = int(response.headers.get(\"Retry-After\", 30))\n",
    "        wait_time = min(retry_after, 30)  # Cap at 30 seconds to avoid overly long delays\n",
    "        logging.warning(f\"Rate limit exceeded, retrying after {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        return get_top_tracks(artist_id, retry_count + 1) if retry_count < 5 else []\n",
    "    elif response.status_code == 401 and retry_count < 5:\n",
    "        logging.warning(\"Token expired, refreshing token...\")\n",
    "        headers['Authorization'] = 'Bearer ' + refresh_token()\n",
    "        return get_top_tracks(artist_id, retry_count + 1)\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def separate_artists(artists, main_artist_name):\n",
    "    \"\"\" Separate main artist from featured artists. \"\"\"\n",
    "    featured_artists = [artist for artist in artists if artist != main_artist_name]\n",
    "    return main_artist_name, ', '.join(featured_artists)\n",
    "\n",
    "def gather_top_tracks(df):\n",
    "    \"\"\" Process each artist and fetch their top tracks. \"\"\"\n",
    "    songs = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Fetching top tracks\"):\n",
    "        artist_id = row['ID']\n",
    "        results = get_top_tracks(artist_id)\n",
    "        for song_id, song_name, artists in results:\n",
    "            main_artist, features = separate_artists(artists, row['Name'])\n",
    "            songs.append([song_id, song_name, main_artist, features])\n",
    "    return songs\n",
    "\n",
    "\n",
    "df_artists = pd.read_csv('Artists.csv')\n",
    "first_part = df_artists.iloc[:4250]\n",
    "logging.info(\"Processing the first 4250 artists...\")\n",
    "song_data = gather_top_tracks(first_part)\n",
    "songs_df = pd.DataFrame(song_data, columns=['Song ID', 'Song Name', 'Main Artist', 'Featured Artists', 'Genres'])\n",
    "\n",
    "# Save the data to CSV\n",
    "songs_df.to_csv('Complete_Songs_with_Artists_and_Features.csv', index=False)\n",
    "logging.info(\"Data saved to Complete_Songs_with_Artists_and_Features.csv.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then created a dataframe of the 4250 artists from the Kaggle dataset containing the following information: Main artist, Top 10 tracks, Artist ID, Genre (categorized by Spotify), Popularity Score, Follower Count, and their URI. See the following code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "songs_df = pd.read_csv('Complete_Songs_with_Artists_and_Features.csv')\n",
    "artists_info_df = pd.read_csv('Artists.csv')\n",
    "\n",
    "songs_df['Main Artist'] = songs_df['Main Artist'].str.strip().str.lower()\n",
    "artists_info_df['Name'] = artists_info_df['Name'].str.strip().str.lower()\n",
    "top_tracks = songs_df.groupby('Main Artist')['Song Name'].apply(list).reset_index()\n",
    "top_tracks.rename(columns={'Main Artist': 'Name'}, inplace=True)\n",
    "final_df = pd.merge(top_tracks, artists_info_df, on='Name', how='left')\n",
    "final_df.rename(columns={'Name': 'Main Artist'}, inplace=True)\n",
    "final_df = final_df[['Main Artist', 'Song Name', 'ID', 'Genres', 'Popularity', 'Followers', 'URI']]\n",
    "\n",
    "# Save the final merged dataset to a new CSV file\n",
    "final_df.to_csv('Final_Artist_Tracks_Info.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now both have a dataframe of the first 4250 artists and the attributes previously mentioned and know which artists are featured on those 4250 artists top tracks. We will now query the same information for the featured artists, so we can merge the data, creating a final dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from tqdm import tqdm\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"#\", client_secret=\"#\"))\n",
    "\n",
    "# Function to search for an artist on Spotify and get their info\n",
    "def get_artist_info(artist_name):\n",
    "    try:\n",
    "        results = sp.search(q='artist:' + artist_name, type='artist', limit=1)\n",
    "        items = results['artists']['items']\n",
    "        if items:\n",
    "            artist = items[0]\n",
    "            return {\n",
    "                'Name': artist['name'],\n",
    "                'ID': artist['id'],\n",
    "                'Genres': ', '.join(artist['genres']),\n",
    "                'Popularity': artist['popularity'],\n",
    "                'Followers': artist['followers']['total'],\n",
    "                'URI': artist['uri']\n",
    "            }\n",
    "    except spotipy.client.SpotifyException as e:\n",
    "        print(f\"Spotify API error for {artist_name}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Read the text file with artist names\n",
    "with open('Unique_Features.txt', 'r') as file:\n",
    "    unique_features = file.read().splitlines()\n",
    "\n",
    "artists_to_query = unique_features\n",
    "artists_info = []\n",
    "for artist_name in tqdm(artists_to_query, desc='Querying artists'):\n",
    "    artist_info = get_artist_info(artist_name)\n",
    "    if artist_info:\n",
    "        artists_info.append(artist_info)\n",
    "    else:\n",
    "        print(f\"No data found for artist: {artist_name}\")\n",
    "\n",
    "artists_df = pd.DataFrame(artists_info)\n",
    "artists_df.to_csv('Complete_Artists_Info.csv', index=False)\n",
    "print(\"Finished collecting all artists' information.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
